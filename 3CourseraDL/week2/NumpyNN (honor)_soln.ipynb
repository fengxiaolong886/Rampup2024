{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your very own neural network\n",
    "\n",
    "In this notebook, we're gonna build a neural network using naught but pure numpy and steel nerves. It's gonna be fun, i promise!\n",
    "\n",
    "![img](https://s27.postimg.org/vpui4r5n7/cartoon-2029952_960_720.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use preloaded keras datasets and models\n",
    "! mkdir -p ~/.keras/datasets\n",
    "! mkdir -p ~/.keras/models\n",
    "! ln -s $(realpath ../readonly/keras/datasets/*) ~/.keras/datasets/\n",
    "! ln -s $(realpath ../readonly/keras/models/*) ~/.keras/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here goes our main class: a layer that can .forward() and .backward()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    A building block. Each layer is capable of performing two things:\n",
    "    \n",
    "    - Process input to get output:           output = layer.forward(input)\n",
    "    \n",
    "    - Propagate gradients through itself:    grad_input = layer.backward(input, grad_output)\n",
    "    \n",
    "    Some layers also have learnable parameters which they update during layer.backward.\n",
    "    \"\"\"\n",
    "    def __init__ (self):\n",
    "        \"\"\"Here you can initialize layer parameters (if any) and auxiliary stuff.\"\"\"\n",
    "        #dummy layer does nothing\n",
    "        pass\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Takes an input data of shape [batch,input_units], returns output data [batch,output_units]\n",
    "        \"\"\"\n",
    "        #The dummy layer just returns whatever it gets as input.\n",
    "        return input\n",
    "\n",
    "    def backward(self,input, grad_output):\n",
    "        \"\"\"\n",
    "        Performs a backpropagation step through the layer, with respect to the given input.\n",
    "        \n",
    "        To compute loss gradients w.r.t input, you need to apply chain rule (backprop):\n",
    "        \n",
    "        d loss / d x  = (d loss / d layer) * (d layer / d x)\n",
    "        \n",
    "        Luckily, you already receive d loss / d layer as input, so you only need to multiply it by d layer / d x.\n",
    "        \n",
    "        If your layer has parameters (e.g. dense layer), you also need to update them here using d loss / d layer\n",
    "        \"\"\"\n",
    "        #The gradient of dummy layer is precisely grad_output, but we'll write it more explicitly\n",
    "        num_units = input.shape[1]\n",
    "        \n",
    "        d_layer_d_input = np.eye(num_units)\n",
    "        \n",
    "        return np.dot(grad_output,d_layer_d_input) #chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The road ahead\n",
    "\n",
    "We're going to build a neural network that classifies MNIST digits. To do so, we'll need a few building blocks:\n",
    "- Dense layer - a fully-connected layer, $f(x)=wx+b$\n",
    "- ReLU layer (or any other nonlinearity you want)\n",
    "- Loss function - crossentropy\n",
    "- Backprop algorithm - a stochastic gradient descent with backpropageted gradients\n",
    "\n",
    "Let's approach them one at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinearity layer\n",
    "\n",
    "This is the simplest layer you can get: it simply applies a nonlinearity to each element of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReLU(Layer):\n",
    "    def __init__(self):\n",
    "        \"\"\"ReLU layer simply applies elementwise rectified linear unit to all inputs\"\"\"\n",
    "        pass\n",
    "    def forward(self,input):\n",
    "        \"\"\"apply elementwise ReLU to [batch,input_units] matrix\"\"\"\n",
    "        #<your code. Try np.maximum>\n",
    "        return np.maximum(0,input)\n",
    "    \n",
    "    def backward(self,input,grad_output):\n",
    "        \"\"\"compute gradient of loss w.r.t. ReLU input\"\"\"\n",
    "        \n",
    "        relu_grad = input>0#<elementwise gradient of sigmoid output w.r.t. sigmoid input>\n",
    "        \n",
    "        #This time we use elemwise product instead of dot cuz sigmoid_grad is written elementwise\n",
    "        return grad_output*relu_grad\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some tests\n",
    "from util import eval_numerical_gradient\n",
    "\n",
    "x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "\n",
    "l = ReLU()\n",
    "\n",
    "grads = l.backward(x,np.ones([10,32])/(32*10))\n",
    "\n",
    "numeric_grads = eval_numerical_gradient(lambda x: l.forward(x).mean(),x=x)\n",
    "\n",
    "assert np.allclose(grads,numeric_grads,rtol=1e-3,atol=0), \"input gradient does not match numeric grad\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instant primer: lambda functions\n",
    "\n",
    "In python, you can define functions in one line using lambda syntax: `lambda param1,param2: expression`\n",
    "\n",
    "For example: `f = lambda x,y: x+y` is equivalent to a normal function:\n",
    "\n",
    "```\n",
    "def f(x,y):\n",
    "    return x+y\n",
    "```\n",
    "For more information, click [here](http://www.secnetix.de/olli/Python/lambda_functions.hawk).\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer\n",
    "\n",
    "Now let's build something more complicated. Unlike nonlinearity, dense layer actually has something to learn.\n",
    "\n",
    "A dense layer applies affine transformation. In a vectorized form, it can be described as:\n",
    "$$f(X)= W \\cdot X + \\vec b $$\n",
    "\n",
    "Where \n",
    "* X is an object-feature matrix of shape [batch_size,num_features],\n",
    "* W is a weight matrix [batch_size,num_outputs] \n",
    "* and b is a vector of num_outputs biases.\n",
    "\n",
    "Both W and b are initialized during layer creation and updated each time backward is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class Dense(Layer):\n",
    "    def __init__(self,input_units,output_units,learning_rate=0.1):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        #initialize weights with small random numbers. We use normal initialization, \n",
    "        #but surely there is something better. Try this once you got it working: http://bit.ly/2vTlmaJ\n",
    "        self.weights = np.random.randn(input_units,output_units)*0.01\n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        #<your code here>\n",
    "        return np.dot(input,self.weights) + self.biases \n",
    "    \n",
    "    def backward(self,input,grad_output):\n",
    "        \n",
    "        #compute d f / d x = d f / d dense * d dense / d x\n",
    "        #where d dense/ d x = weights transposed\n",
    "        #<your code here>\n",
    "        grad_input = np.dot(grad_output, self.weights.T) \n",
    "        \n",
    "        #compute gradient w.r.t. weights and biases\n",
    "        grad_weights = np.dot(input.T,grad_output)/input.shape[0] #<your code here>\n",
    "        grad_biases = grad_output.mean(axis=0) #<your code here>\n",
    "        \n",
    "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
    "        #Here we perform stochastic gradient descent step. \n",
    "        #later on, you can try replacing that with something better.\n",
    "        self.weights = self.weights - self.learning_rate*grad_weights\n",
    "        self.biases = self.biases - self.learning_rate*grad_biases\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the dense layer\n",
    "\n",
    "Here we have a few tests to make sure your dense layer works properly. You can just run them, get 3 \"well done\"s and forget they ever existed.\n",
    "\n",
    "... or not get 3 \"well done\"s and go fix stuff. If that is the case, here are some tips for you:\n",
    "* Make sure you compute gradients for W and b as __mean gradient over batch__, not sums of gradients.\n",
    "* If you're debugging, try saving gradients in class fields, like \"self.grad_w = grad_w\" or print first 3-5 weights. This helps debugging.\n",
    "* If nothing else helps, try ignoring tests and proceed to network training. If it trains alright, you may be off by something that does not affect network training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "l = Dense(128,150)\n",
    "\n",
    "assert -0.05 < l.weights.mean() < 0.05 and 1e-3 < l.weights.std() < 1e-1, \"weights must be zero mean and have small variance.\"\\\n",
    "                                                                  \"If you know what you're doing, remove this assertion.\"\n",
    "assert -0.05 < l.biases.mean() < 0.05, \"Biases must be zero mean. Ignore if you have a reason to do otherwise.\"\n",
    "\n",
    "#to test outputs, we explicitly set weights with fixed values. DO NOT DO THAT IN ACTUAL NETWORK!\n",
    "l = Dense(3,4)\n",
    "\n",
    "x = np.linspace(-1,1,2*3).reshape([2,3])\n",
    "l.weights = np.linspace(-1,1,3*4).reshape([3,4])\n",
    "l.biases = np.linspace(-1,1,4)\n",
    "\n",
    "assert np.allclose(l.forward(x),np.array([[ 0.07272727,  0.41212121,  0.75151515,  1.09090909],\n",
    "                                          [-0.90909091,  0.08484848,  1.07878788,  2.07272727]]))\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# to test grads, we use gradients obtained via finite differences\n",
    "\n",
    "from util import eval_numerical_gradient\n",
    "\n",
    "x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "l = Dense(32,64,learning_rate=0)\n",
    "\n",
    "numeric_grads = eval_numerical_gradient(lambda x: l.forward(x).sum(),x)\n",
    "grads = l.backward(x,np.ones([10,64]))\n",
    "\n",
    "assert np.allclose(grads,numeric_grads,rtol=1e-3,atol=0), \"input gradient does not match numeric grad\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "#test gradients w.r.t. params\n",
    "def compute_out_given_wb(w,b):\n",
    "    l = Dense(32,64,learning_rate=1)\n",
    "    l.weights = np.array(w)\n",
    "    l.biases = np.array(b)\n",
    "    x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "    return l.forward(x)\n",
    "    \n",
    "def compute_grad_by_params(w,b):\n",
    "    l = Dense(32,64,learning_rate=1)\n",
    "    l.weights = np.array(w)\n",
    "    l.biases = np.array(b)\n",
    "    x = np.linspace(-1,1,10*32).reshape([10,32])\n",
    "    l.backward(x,np.ones([10,64]))\n",
    "    return w - l.weights, b - l.biases\n",
    "    \n",
    "    \n",
    "w,b = np.random.randn(32,64), np.linspace(-1,1,64)\n",
    "\n",
    "\n",
    "numeric_dw = eval_numerical_gradient(lambda w: compute_out_given_wb(w,b).mean(0).sum(),w )\n",
    "numeric_db = eval_numerical_gradient(lambda b: compute_out_given_wb(w,b).mean(0).sum(),b )\n",
    "grad_w,grad_b = compute_grad_by_params(w,b)\n",
    "\n",
    "assert np.allclose(numeric_dw,grad_w,rtol=1e-3,atol=0), \"weight gradient does not match numeric weight gradient\"\n",
    "assert np.allclose(numeric_db,grad_b,rtol=1e-3,atol=0), \"weight gradient does not match numeric weight gradient\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The loss function\n",
    "\n",
    "Since we want to predict probabilities, it would be logical for us to define softmax nonlinearity on top of our network and compute loss given predicted probabilities. However, there is a better way to do so.\n",
    "\n",
    "If you write down the expression for crossentropy as a function of softmax logits (a), you'll see:\n",
    "\n",
    "$$ loss = - log \\space {e^{a_{correct}} \\over {\\underset i \\sum e^{a_i} } } $$\n",
    "\n",
    "If you take a closer look, ya'll see that it can be rewritten as:\n",
    "\n",
    "$$ loss = - a_{correct} + log {\\underset i \\sum e^{a_i} } $$\n",
    "\n",
    "It's called Log-softmax and it's better than naive log(softmax(a)) in all aspects:\n",
    "* Better numerical stability\n",
    "* Easier to get derivative right\n",
    "* Marginally faster to compute\n",
    "\n",
    "So why not just use log-softmax throughout our computation and never actually bother to estimate probabilities.\n",
    "\n",
    "Here you are! We've defined both loss functions for you so that you could focus on neural network part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    logits_for_answers = logits[np.arange(len(logits)),reference_answers]\n",
    "    \n",
    "    xentropy = - logits_for_answers + np.log(np.sum(np.exp(logits),axis=-1))\n",
    "    \n",
    "    return xentropy\n",
    "\n",
    "def grad_softmax_crossentropy_with_logits(logits,reference_answers):\n",
    "    \"\"\"Compute crossentropy gradient from logits[batch,n_classes] and ids of correct answers\"\"\"\n",
    "    ones_for_answers = np.zeros_like(logits)\n",
    "    ones_for_answers[np.arange(len(logits)),reference_answers] = 1\n",
    "    \n",
    "    softmax = np.exp(logits) / np.exp(logits).sum(axis=-1,keepdims=True)\n",
    "    \n",
    "    return - ones_for_answers + softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = np.linspace(-1,1,500).reshape([50,10])\n",
    "answers = np.arange(50)%10\n",
    "\n",
    "softmax_crossentropy_with_logits(logits,answers)\n",
    "grads = grad_softmax_crossentropy_with_logits(logits,answers)\n",
    "numeric_grads = eval_numerical_gradient(lambda l: softmax_crossentropy_with_logits(l,answers).sum(),logits)\n",
    "\n",
    "assert np.allclose(numeric_grads,grads,rtol=1e-3,atol=0), \"omfg, reference implementation just failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full network\n",
    "\n",
    "Now let's combine what we just built into a working neural network. As we announced, we're gonna use this monster to classify handwritten digits, so let's get them loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAF1CAYAAADx1LGMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu0VXW5//HPA0Le8gIWEohoA2mQQzHRyEgpsIx0iJkU\nQwWHHnEML0cbxtH8aWqlh/JS3pOjyEWPWocIMk0NUXJoHNFQEUTNIwQheENALQOe3x9rMtru73ez\n115rrrnWd+33a4w99lrPmpdnwsPDXPPynebuAgCkp0u9EwAAVIYGDgCJooEDQKJo4ACQKBo4ACSK\nBg4AiaKBF8zMHjWzfyt6XqDWqO3i0cArZGavmdnIeufRFjM7xcw2m9nGFj/D650XGl+j17Ykmdl3\nzex1M1tvZlPM7GP1zqkeaODN7Ul337nFz6P1Tgiolpl9TdKFkkZI2lvSvpIur2tSdUIDz5mZ7W5m\n95nZG2b2Tva6b6vJPm1m/5vtPcw2sx4t5h9qZk+Y2Toze5a9ZjSKBqrt8ZJud/cX3P0dST+UdEqF\ny0oaDTx/XSTdodKeQT9JH0i6sdU04ySdKqm3pE2SrpckM+sj6XeSfiyph6TvSZppZp9ovRIz65f9\nQ+i3jVwOMrM3zewlM7vEzLarbtPQyTVKbX9W0rMt3j8rqZeZ9axwu5JFA8+Zu7/l7jPd/X133yDp\nCklHtJpshrsvdvf3JF0iaYyZdZV0kqT73f1+d9/i7g9LWihpVGQ9K9x9N3df0UYq8yXtL+mTko6X\nNFbSxFw2Ep1SA9X2zpLebfF+ffb741VsXpJo4Dkzsx3N7FYzW25m61VqpLtlRbzVX1u8Xi6pm6Q9\nVNqzOSHb+1hnZuskDVNpb6ZD3P1Vd/+/7B/L8yp9zfxWpdsFNEptS9ooaZcW73fNfm+oYFlJo4Hn\n73xJAyV93t13kXR4FrcW0+zV4nU/Sf+U9KZKxT8j2/vY+rOTu0/KIS9vlQPQUY1S2y9IOrDF+wMl\nrXH3typYVtJo4NXpZmbbt/jZTqWvcR9IWpedwLk0Mt9JZjbIzHZUac/4f9x9s6Q7JR1jZl8zs67Z\nModHThS1y8y+bma9stefUenr7OwKtxOdT8PWtqTpkk7L1rO7SrU9tZKNTB0NvDr3q1TQW38uk/Rz\nSTuotNfxJ0m/j8w3Q6WCe13S9pL+XZLc/a+SjpV0kaQ3VNprmajI31N2omfjNk70jJD0nJm9l+X5\na0lXVrCN6Jwatrbd/feSfippnkqHaf5P8f9Mmp7xQAcASBN74ACQKBo4ACSKBg4AiaKBA0Ciqmrg\nZnaUmS0zs1fM7MK8kgLqjdpGCiq+CiW7++olSUdKWinpKUlj3X3JNubhkhfkyt1zvzmJ2kYjKKe2\nq9kDP1TSK9kt2x9Kukel6zyB1FHbSEI1DbyPPjruwcos9hFmNsHMFprZwirWBRSJ2kYSaj68qLtP\nljRZ4msmmgu1jXqrZg98lT46cE3fLAakjtpGEqpp4E9JGmBm+5hZd0nfkTQnn7SAuqK2kYSKD6G4\n+yYzO1vSg5K6Spri7i/klhlQJ9Q2UlHoYFYcJ0TeanEZYSWobeSt1pcRAgDqiAYOAImigQNAomjg\nAJAoGjgAJIoGDgCJooEDQKJo4ACQKBo4ACSKBg4AiaKBA0CiaOAAkKiaP9ABANpz8MEHB7Gzzz47\niI0bNy46//Tp04PYDTfcEMSeeeaZCrJrXOyBA0CiaOAAkCgaOAAkigYOAImq6iSmmb0maYOkzZI2\nufuQPJIC6o3aRgqqeqRaVuRD3P3NMqfv1I+d6tq1axDbddddq1pm7Ez9jjvuGJ124MCBQeyss84K\nYldffXV0/rFjxwaxv//970Fs0qRJ0fkvv/zyaLwatXqkGrVdG4MHD47GH3nkkSC2yy67VLWud999\nN4j17NmzqmUWiUeqAUATq7aBu6Q/mNnTZjYhj4SABkFto+FVeyPPMHdfZWaflPSwmb3o7vNbTpAV\nP/8AkBpqGw2vqj1wd1+V/V4raZakQyPTTHb3IZwEQkqobaSg4j1wM9tJUhd335C9/qqkH+aWWZ31\n69cviHXv3j2IHXbYYdH5hw0bFsR22223IHb88cdXkF1lVq5cGcSuv/76IHbcccdF59+wYUMQe/bZ\nZ4PYY489VkF2jaPZa7sohx4a/J+nmTNnRqeNncyPXWARq0FJ+vDDD4NY7ITl0KFDo/PHbrGPLbPR\nVHMIpZekWWa2dTn/7e6/zyUroL6obSSh4gbu7q9KOjDHXICGQG0jFVxGCACJooEDQKKquhOzwytr\nwLvVOnJnWLV3TRZly5Yt0fipp54axDZu3Fj2clevXh3E3nnnnSC2bNmyspdZrVrdidlRjVjbtRK7\n0/dzn/tcELvzzjuDWN++faPLzM43fESsN7U1nvdPf/rTIHbPPfeUtR5Juvjii4PYf/7nf0anLQp3\nYgJAE6OBA0CiaOAAkCgaOAAkigYOAInq9E+lX7FiRTT+1ltvBbGirkJZsGBBNL5u3bog9uUvfzmI\ntXUL8IwZM6pLDJB06623BrHYWPG1ELvaRZJ23nnnIBYb0mH48OHR+Q844ICq8qoX9sABIFE0cABI\nFA0cABJFAweARHX6k5hvv/12ND5x4sQgdvTRRwexP//5z9H5Y+NsxyxatCiIHXnkkdFp33vvvSD2\n2c9+Noide+65Za0b2JaDDz44Gv/GN74RxNq6Rb21tsaK/+1vfxvEYg/X/tvf/hadP/bvMDbMw1e+\n8pXo/OXm32jYAweARNHAASBRNHAASBQNHAAS1e544GY2RdLRkta6+/5ZrIekeyX1l/SapDHuHp4x\nCJeV9JjJu+yySxBr6yGrsbvVTjvttCB20kknBbG77767guw6p2rGA6e2/yU2Ln5sTHwp/u8g5oEH\nHghibd2xecQRRwSx2N2Rt912W3T+N954o6ycNm/eHI2///77ZeXU1njktZDXeOBTJR3VKnahpLnu\nPkDS3Ow9kJqporaRsHYbuLvPl9T6WrtjJU3LXk+TNDrnvICao7aRukqvA+/l7lufr/W6pF5tTWhm\nEyRNqHA9QNGobSSj6ht53N23dfzP3SdLmiylf5wQnQu1jUZX6VUoa8ystyRlv9fmlxJQV9Q2klHp\nHvgcSeMlTcp+z84towa2fv36sqd99913y5ru9NNPD2L33ntvdNq2njaPXDV9be+3335BLDZ0RFvj\n37/55ptBbPXq1UFs2rRpQWzjxo3RZf7ud78rK1YrO+ywQxA7//zzg9iJJ55YRDpla3cP3MzulvSk\npIFmttLMTlOpuI80s5cljczeA0mhtpG6dvfA3b2tR22MyDkXoFDUNlLHnZgAkCgaOAAkqtOPB14r\nl112WRCLja8cu1135MiR0WU+9NBDVeeFzuNjH/tYNB4bZ3vUqFFBrK1hIsaNGxfEFi5cGMRiJwZT\n0q9fv3qn0C72wAEgUTRwAEgUDRwAEkUDB4BEtTseeK4r6+TjRXz6058OYrHxhdetWxedf968eUEs\ndvLopptuis5f5N91UaoZDzxPjVjbQ4cOjcYff/zxsuYfMSJ+OXxbDyZOQVvjgcf+bTz55JNB7Etf\n+lLuObUlr/HAAQANiAYOAImigQNAomjgAJAo7sQs0F/+8pcgdsoppwSxO+64Izr/ySefXFZsp512\nis4/ffr0IBYbBhTN4dprr43GzcJzY7ETkymfrGxLly7xfdZUh2pmDxwAEkUDB4BE0cABIFE0cABI\nVDmPVJtiZmvNbHGL2GVmtsrMFmU/4ViUQIOjtpG6cq5CmSrpRkmtL2H4mbuHAwujQ2bNmhXEXn75\n5ei0sasKYrc7X3nlldH599577yB2xRVXBLFVq1ZF529CU9UktX300UcHscGDB0enjd02PmfOnNxz\nakRtXW0S+zNZtGhRrdOpWrt74O4+X9LbBeQCFIraRuqqOQZ+jpk9l30N3T23jID6o7aRhEob+C2S\n9pU0WNJqSde0NaGZTTCzhWYWDpsHNB5qG8moqIG7+xp33+zuWyT9l6RDtzHtZHcf4u5DKk0SKAq1\njZRUdCu9mfV29633YB8nafG2pkfHLF4c/+McM2ZMEDvmmGOCWFu34p9xxhlBbMCAAUHsyCOPbC/F\nppVqbcceINy9e/fotGvXrg1i9957b+45FSn2AOfYg8Xb8sgjjwSx73//+9WkVIh2G7iZ3S1puKQ9\nzGylpEslDTezwZJc0muSws4ANDhqG6lrt4G7+9hI+PYa5AIUitpG6rgTEwASRQMHgEQxHnhCYg87\nnjFjRhC77bbbovNvt13413344YcHseHDh0fnf/TRR7edIJLwj3/8I4ilMi587GSlJF188cVBbOLE\niUFs5cqV0fmvuSa8WnTjxo0dzK547IEDQKJo4ACQKBo4ACSKBg4AiaKBA0CiuAqlAR1wwAHR+Le+\n9a0gdsghhwSx2NUmbVmyZEkQmz9/ftnzIz2pjP0dG888dmWJJH37298OYrNnzw5ixx9/fPWJNRD2\nwAEgUTRwAEgUDRwAEkUDB4BEcRKzQAMHDgxiZ599dhD75je/GZ1/zz33rGr9mzdvDmKxW6jbevAr\nGpeZlRWTpNGjRwexc889N/ecOuK73/1uELvkkkuC2K677hqd/6677gpi48aNqz6xBsceOAAkigYO\nAImigQNAomjgAJCocp6JuZek6ZJ6qfScwMnufp2Z9ZB0r6T+Kj07cIy7v1O7VBtTWycWx44Nn9YV\nO2HZv3//vFPSwoULo/ErrrgiiKVyV14tNFNtu3tZMSles9dff30QmzJlSnT+t956K4gNHTo0iJ18\n8slB7MADD4wus2/fvkFsxYoVQezBBx+Mzn/zzTdH482unD3wTZLOd/dBkoZKOsvMBkm6UNJcdx8g\naW72HkgJtY2ktdvA3X21uz+Tvd4gaamkPpKOlTQtm2yapPDaJKCBUdtIXYeuAzez/pIOkrRAUi93\n33oR8esqfQ2NzTNB0oTKUwRqj9pGiso+iWlmO0uaKek8d1/f8jMvHWyLHnBz98nuPsTdh1SVKVAj\n1DZSVVYDN7NuKhX4Xe7+6yy8xsx6Z5/3lrS2NikCtUNtI2XlXIVikm6XtNTdr23x0RxJ4yVNyn6H\ng+8mrFev8FvzoEGDgtiNN94Ynf8zn/lM7jktWLAgiF111VVBLDYOssQt8q111tru2rVrEDvzzDOD\nWFtjZ69fvz6IDRgwoKqcnnjiiSA2b968IPaDH/ygqvU0m3KOgX9R0smSnjezRVnsIpWK+5dmdpqk\n5ZLG1CZFoGaobSSt3Qbu7o9Lio+KI43INx2gONQ2UsedmACQKBo4ACTK2rrdtiYrMytuZRE9evQI\nYrfeemt02tgDVffdd9/cc4qdvLnmmmui08ZuI/7ggw9yzykl7t7WIZBC1bu2Y7ei/+pXv4pOG3sQ\ndkxb44mX2zNit9zfc8890WnrPR55IyqnttkDB4BE0cABIFE0cABIFA0cABKV/EnMz3/+89H4xIkT\ng9ihhx4axPr06ZN3SpKk999/P4jFxly+8sorg9h7771Xk5yaEScx29a7d+9o/IwzzghiF198cRDr\nyEnM6667LojdcsstQeyVV16JLhMhTmICQBOjgQNAomjgAJAoGjgAJIoGDgCJSv4qlEmTJkXjsatQ\nOmLJkiVB7L777gtimzZtis4fux1+3bp1VeWEEFehoFlxFQoANDEaOAAkigYOAIlqt4Gb2V5mNs/M\nlpjZC2Z2bha/zMxWmdmi7GdU7dMF8kNtI3XtnsTMnsrd292fMbOPS3pa0miVnhO40d2vLntlnOhB\nzqo5iUlto5GVU9vlPBNztaTV2esNZrZUUm0GEAEKRG0jdR06Bm5m/SUdJGlBFjrHzJ4zsylmtnvO\nuQGFobaRorIbuJntLGmmpPPcfb2kWyTtK2mwSnsx0eeAmdkEM1toZgtzyBfIHbWNVJV1I4+ZdZN0\nn6QH3f3ayOf9Jd3n7vu3sxyOEyJX1d7IQ22jUeVyI4+VBgW+XdLSlgWenQDa6jhJiytJEqgXahup\nK+cqlGGS/ijpeUlbsvBFksaq9BXTJb0m6YzspNC2lsVeCnJV5VUo1DYaVjm1nfxYKOjcGAsFzYqx\nUACgidHAASBRNHAASBQNHAASRQMHgETRwAEgUTRwAEgUDRwAEtXucLI5e1PS8uz1Htn7ZtJs29To\n27N3vRNoYWttN/qfWSXYpuKVVduF3on5kRWbLXT3IXVZeY002zY12/YUoRn/zNimxsUhFABIFA0c\nABJVzwY+uY7rrpVm26Zm254iNOOfGdvUoOp2DBwAUB0OoQBAogpv4GZ2lJktM7NXzOzCotefh+xB\nt2vNbHGLWA8ze9jMXs5+J/UgXDPby8zmmdkSM3vBzM7N4klvV5Go7cbT7HVdaAM3s66SbpL0dUmD\nJI01s0FF5pCTqZKOahW7UNJcdx8gaW72PiWbJJ3v7oMkDZV0VvZ3k/p2FYLablhNXddF74EfKukV\nd3/V3T+UdI+kYwvOoWruPl/S263Cx0qalr2eJml0oUlVyd1Xu/sz2esNkpZK6qPEt6tA1HYDava6\nLrqB95H01xbvV2axZtCrxXMTX5fUq57JVCN7EvtBkhaoibarxqjtBteMdc1JzBrw0qU9SV7eY2Y7\nS5op6Tx3X9/ys5S3C/lItQaata6LbuCrJO3V4n3fLNYM1phZb0nKfq+tcz4dZmbdVCryu9z911k4\n+e0qCLXdoJq5rotu4E9JGmBm+5hZd0nfkTSn4BxqZY6k8dnr8ZJm1zGXDjMzk3S7pKXufm2Lj5Le\nrgJR2w2o6eva3Qv9kTRK0kuS/iLp/xW9/py24W5JqyX9U6VjnadJ6qnS2eyXJf1BUo825n1U0r9V\nuN6K5y1j2cNU+hr5nKRF2c+ocreLH2q7EWu72eu66OFk5e73S7q/6PXmyd3Hmtlrkr7u7n9o8dGI\nOqW0TWY2V9JXJHVz902xadz9cUnWxiIacrsaDbVdDDPbX9I1kg6W1NPd26rbpq9rTmI2OTM7UVK3\neucB5Oifkn6p0reDTo0GnjMz293M7jOzN8zsnex131aTfdrM/tfM1pvZbDPr0WL+oWb2hJmtM7Nn\nzWx4FbnsKulSSf9R6TKArRqltt19mbvfLumFKjanKdDA89dF0h0qPVGjn6QPJN3Yappxkk6V1Ful\nO8WulyQz6yPpd5J+LKmHpO9Jmmlmn2i9EjPrl/1D6LeNXK6UdItK17kC1Wqk2oZo4Llz97fcfaa7\nv++lO7+ukHREq8lmuPtid39P0iWSxmS3Yp8k6X53v9/dt7j7w5IWqnTSpfV6Vrj7bu6+IpaHmQ2R\n9EVJN+S4eejEGqW28S+Fn8Rsdma2o6SfqTSexNYBcj5uZl3dfXP2vuUde8tVOka9h0p7NieY2TEt\nPu8maV4Hc+gi6WZJ57r7ptKVVEB1GqG28VE08PydL2mgpM+7++tmNljSn/XRM+Etb/jop9JJmTdV\nKv4Z7n56lTnsImmIpHuz5t01i680sxPc/Y9VLh+dUyPUNlrgEEp1upnZ9i1+tpP0cZWODa7LTuBc\nGpnvJDMblO3R/FDS/2R7MHdKOsbMvmZmXbNlDo+cKGrPu5I+JWlw9rP1a+rBKo0DAbSnUWtbVrK9\npO7Z++3N7GOVbmjKaODVuV+lgt76c5mkn0vaQaW9jj9J+n1kvhkqDdv5uqTtJf27JLn7X1UaJe0i\nSW+otNcyUZG/p+xEz8bYiR4veX3rT7YsSVrjpZHygPY0ZG1n9s5y2noVygeSlnVw+5oCj1QDgESx\nBw4AiaKBA0CiaOAAkCgaOAAkqqoGbk3wFG4ghtpGCiq+CiW7PfYlSUeqNG7wU5LGuvuSbczDJS/I\n1baGEq0UtY1GUE5tV7MH3hRP4QYiqG0koZoGXtZTuM1sgpktNLOFVawLKBK1jSTUfCwUd58sabLE\n10w0F2ob9VbNHngzP4UbnRu1jSRU08Cb+Snc6NyobSSh4kMo2TjTZ0t6UKXhSqe4e6d/xBHSR20j\nFYUOZsVxQuStFpcRVoLaRt5qfRkhAKCOaOAAkCgaOAAkigYOAImigQNAomjgAJAoGjgAJIoGDgCJ\nooEDQKJo4ACQKBo4ACSKBg4AiaKBA0CiaOAAkCgaOAAkigYOAImigQNAoqp6Kr2ZvSZpg6TNkja5\n+5A8kgLqjdpGCqpq4Jkvu/ubOSwHDWLEiBHR+F133RXEjjjiiCC2bNmy3HOqE2o7ERdffHEQu/zy\ny4NYly7xgw7Dhw8PYo899ljVedUah1AAIFHVNnCX9Acze9rMJuSRENAgqG00vGoPoQxz91Vm9klJ\nD5vZi+4+v+UEWfHzDwCpobbR8KraA3f3VdnvtZJmSTo0Ms1kdx/CSSCkhNpGCireAzeznSR1cfcN\n2euvSvphbpmV6fDDD4/Ge/bsGcRmzZpV63SawiGHHBKNP/XUUwVnUh+NUtsInXLKKdH4BRdcEMS2\nbNlS9nLdvdKU6qqaQyi9JM0ys63L+W93/30uWQH1RW0jCRU3cHd/VdKBOeYCNARqG6ngMkIASBQN\nHAASlcedmHUVu4NKkgYMGBDEOIkZit2Zts8++0Sn3XvvvYNYdpwYKESsBiVp++23LziTxsAeOAAk\nigYOAImigQNAomjgAJAoGjgAJCr5q1DGjRsXjT/55JMFZ5Km3r17B7HTTz89Ou2dd94ZxF588cXc\ncwIkaeTIkUHsnHPOKXv+WG0effTR0WnXrFlTfmINhD1wAEgUDRwAEkUDB4BE0cABIFHJn8Rs6yGl\nKM9tt91W9rQvv/xyDTNBZzZs2LAgdscddwSxXXfdtexlXnXVVUFs+fLlHUuswdH9ACBRNHAASBQN\nHAASRQMHgES1exLTzKZIOlrSWnffP4v1kHSvpP6SXpM0xt3fqV2aJQcccEAQ69WrV61X29Q6clLo\n4YcfrmEmxWuk2u7sxo8fH8Q+9alPlT3/o48+GsSmT59eTUpJKGcPfKqko1rFLpQ0190HSJqbvQdS\nM1XUNhLWbgN39/mS3m4VPlbStOz1NEmjc84LqDlqG6mr9DrwXu6+Onv9uqQ2j2OY2QRJEypcD1A0\nahvJqPpGHnd3M/NtfD5Z0mRJ2tZ0QKOhttHoKr0KZY2Z9Zak7Pfa/FIC6oraRjIq3QOfI2m8pEnZ\n79m5ZbQNo0aNCmI77LBDEatuCrErdtp6An3MqlWr8kynUdWltjuLPfbYIxo/9dRTg9iWLVuC2Lp1\n66Lz//jHP64usUS1uwduZndLelLSQDNbaWanqVTcR5rZy5JGZu+BpFDbSF27e+DuPraNj0bknAtQ\nKGobqeNOTABIFA0cABKV1HjgAwcOLHvaF154oYaZpOnqq68OYrETmy+99FJ0/g0bNuSeE5pX//79\ng9jMmTOrWuYNN9wQjc+bN6+q5aaKPXAASBQNHAASRQMHgETRwAEgUUmdxOyIp556qt4p5G6XXXYJ\nYkcd1Xo0VOmkk06Kzv/Vr361rPX86Ec/isbbugsOiInVZmxM/7bMnTs3iF133XVV5dRs2AMHgETR\nwAEgUTRwAEgUDRwAEtW0JzF79OiR+zIPPPDAIGZm0WlHjhwZxPr27RvEunfvHsROPPHE6DK7dAn/\nv/3ggw+C2IIFC6Lz/+Mf/whi220XlsDTTz8dnR9oy+jR4ZPnJk0qfyDHxx9/PIjFHnT87rvvdiyx\nJsceOAAkigYOAImigQNAomjgAJCoch6pNsXM1prZ4haxy8xslZktyn7Ch1UCDY7aRurKuQplqqQb\nJU1vFf+Zu4cDTNdQ7IoLd49O+4tf/CKIXXTRRVWtP3YbcFtXoWzatCmIvf/++0FsyZIlQWzKlCnR\nZS5cuDCIPfbYY0FszZo10flXrlwZxGIPhX7xxRej8zehqWqQ2k5JLcb5fvXVV4NYW3WMf2l3D9zd\n50t6u4BcgEJR20hdNcfAzzGz57KvobvnlhFQf9Q2klBpA79F0r6SBktaLematiY0swlmttDMwu//\nQOOhtpGMihq4u69x983uvkXSf0k6dBvTTnb3Ie4+pNIkgaJQ20hJRbfSm1lvd1+dvT1O0uJtTZ+X\nM888M4gtX748Ou1hhx2W+/pXrFgRxH7zm99Ep126dGkQ+9Of/pR7TjETJkyIxj/xiU8EsdjJo86s\nXrWdkgsuuCCIbdmypaplduS2e/xLuw3czO6WNFzSHma2UtKlkoab2WBJLuk1SWfUMEegJqhtpK7d\nBu7uYyPh22uQC1Aoahup405MAEgUDRwAEpX8eOA/+clP6p1CwxkxYkTZ01Z7Bx2a1+DBg6Pxch+O\nHTN79uxofNmyZRUvszNjDxwAEkUDB4BE0cABIFE0cABIFA0cABKV/FUoqM6sWbPqnQIa1EMPPRSN\n7757eQM0xoaOOOWUU6pJCa2wBw4AiaKBA0CiaOAAkCgaOAAkipOYAKJ69uwZjZc79vfNN98cxDZu\n3FhVTvgo9sABIFE0cABIFA0cABJFAweARJXzTMy9JE2X1Eul5wROdvfrzKyHpHsl9Vfp2YFj3P2d\n2qWKaplZENtvv/2CWFEPX643avtf7rjjjiDWpUt1+3dPPPFEVfOjfeX8DW2SdL67D5I0VNJZZjZI\n0oWS5rr7AElzs/dASqhtJK3dBu7uq939mez1BklLJfWRdKykadlk0ySNrlWSQC1Q20hdh64DN7P+\nkg6StEBSL3dfnX30ukpfQ2PzTJA0ofIUgdqjtpGisg9ymdnOkmZKOs/d17f8zN1dpWOIAXef7O5D\n3H1IVZkCNUJtI1VlNXAz66ZSgd/l7r/OwmvMrHf2eW9Ja2uTIlA71DZSVs5VKCbpdklL3f3aFh/N\nkTRe0qTsd/xx02gYpZ3Jj6r2SoOUddbajj1tfuTIkUGsrVvmP/zwwyB20003BbE1a9ZUkB06opxj\n4F+UdLKk581sURa7SKXi/qWZnSZpuaQxtUkRqBlqG0lrt4G7++OSwguIS0bkmw5QHGobqeu8358B\nIHE0cABIFOOBd3Jf+MIXgtjUqVOLTwSF2W233YLYnnvuWfb8q1atCmLf+973qsoJlWEPHAASRQMH\ngETRwAF4OrTvAAAEF0lEQVQgUTRwAEgUJzE7kdh44ADSxR44ACSKBg4AiaKBA0CiaOAAkCgaOAAk\niqtQmtADDzwQjZ9wwgkFZ4JG9OKLLwax2BPkhw0bVkQ6qAJ74ACQKBo4ACSKBg4AiWq3gZvZXmY2\nz8yWmNkLZnZuFr/MzFaZ2aLsZ1Tt0wXyQ20jdRZ70O1HJig9lbu3uz9jZh+X9LSk0So9J3Cju19d\n9srMtr0yoIPcveLxAahtNLJyarucZ2KulrQ6e73BzJZK6lN9ekB9UdtIXYeOgZtZf0kHSVqQhc4x\ns+fMbIqZ7Z5zbkBhqG2kqOwGbmY7S5op6Tx3Xy/pFkn7Shqs0l7MNW3MN8HMFprZwhzyBXJHbSNV\n7R4DlyQz6ybpPkkPuvu1kc/7S7rP3fdvZzkcJ0SuqjkGLlHbaFzl1HY5V6GYpNslLW1Z4NkJoK2O\nk7S4kiSBeqG2kbpyrkIZJumPkp6XtCULXyRprEpfMV3Sa5LOyE4KbWtZ7KUgV1VehUJto2GVU9tl\nHULJC0WOvFV7CCUv1DbylsshFABAY6KBA0CiaOAAkCgaOAAkigYOAImigQNAomjgAJAoGjgAJKro\nhxq/KWl59nqP7H0zabZtavTt2bveCbSwtbYb/c+sEmxT8cqq7ULvxPzIis0WuvuQuqy8Rpptm5pt\ne4rQjH9mbFPj4hAKACSKBg4AiapnA59cx3XXSrNtU7NtTxGa8c+MbWpQdTsGDgCoDodQACBRhTdw\nMzvKzJaZ2StmdmHR689D9qDbtWa2uEWsh5k9bGYvZ7+TehCume1lZvPMbImZvWBm52bxpLerSNR2\n42n2ui60gZtZV0k3Sfq6pEGSxprZoCJzyMlUSUe1il0oaa67D5A0N3ufkk2Sznf3QZKGSjor+7tJ\nfbsKQW03rKau66L3wA+V9Iq7v+ruH0q6R9KxBedQNXefL+ntVuFjJU3LXk+TNLrQpKrk7qvd/Zns\n9QZJSyX1UeLbVSBquwE1e10X3cD7SPpri/crs1gz6NXiuYmvS+pVz2SqkT2J/SBJC9RE21Vj1HaD\na8a65iRmDXjp0p4kL+8xs50lzZR0nruvb/lZytuFfKRaA81a10U38FWS9mrxvm8WawZrzKy3JGW/\n19Y5nw4zs24qFfld7v7rLJz8dhWE2m5QzVzXRTfwpyQNMLN9zKy7pO9ImlNwDrUyR9L47PV4SbPr\nmEuHmZlJul3SUne/tsVHSW9XgajtBtTsdV34jTxmNkrSzyV1lTTF3a8oNIEcmNndkoarNKLZGkmX\nSvqNpF9K6qfSqHRj3L31yaCGZWbDJP1R0vOStmThi1Q6XpjsdhWJ2m48zV7X3IkJAIniJCYAJIoG\nDgCJooEDQKJo4ACQKBo4ACSKBg4AiaKBA0CiaOAAkKj/D+CzS1p6Mu98AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x286121ed048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset(flatten=True)\n",
    "\n",
    "plt.figure(figsize=[6,6])\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.title(\"Label: %i\"%y_train[i])\n",
    "    plt.imshow(X_train[i].reshape([28,28]),cmap='gray');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define network as a list of layers, each applied on top of previous one. In this setting, computing predictions and training becomes trivial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = []\n",
    "network.append(Dense(X_train.shape[1],100))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(100,200))\n",
    "network.append(ReLU())\n",
    "network.append(Dense(200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward(network,X):\n",
    "    \"\"\"\n",
    "    Compute activations of all network layers by applying them sequentially.\n",
    "    Return a list of activations for each layer. \n",
    "    Make sure last activation corresponds to network logits.\n",
    "    \"\"\"\n",
    "    activations = []\n",
    "    input = X\n",
    "\n",
    "    #<your code here>\n",
    "    for layer in network:\n",
    "        activations.append(layer.forward(input))\n",
    "        input = activations[-1]\n",
    "        \n",
    "        \n",
    "    assert len(activations) == len(network)\n",
    "    return activations\n",
    "\n",
    "def predict(network,X):\n",
    "    \"\"\"\n",
    "    Compute network predictions.\n",
    "    \"\"\"\n",
    "    logits = forward(network,X)[-1]\n",
    "    return logits.argmax(axis=-1)\n",
    "\n",
    "def train(network,X,y):\n",
    "    \"\"\"\n",
    "    Train your network on a given batch of X and y.\n",
    "    You first need to run forward to get all layer activations.\n",
    "    Then you can run layer.backward going from last to first layer.\n",
    "    \n",
    "    After you called backward for all layers, all Dense layers have already made one gradient step.\n",
    "    \"\"\"\n",
    "    \n",
    "    #get layer activations\n",
    "    layer_activations = forward(network,X)\n",
    "    layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
    "    logits = layer_activations[-1]\n",
    "    \n",
    "    #Compute loss and initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits,y)\n",
    "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
    "    \n",
    "    #<your code: propagate gradients through the network>\n",
    "    for layer_i in range(len(network))[::-1]:\n",
    "        layer = network[layer_i]\n",
    "        \n",
    "        loss_grad = layer.backward(layer_inputs[layer_i],loss_grad) #grad w.r.t. input, also weight updates\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of tests, we provide you with a training loop that prints training and validation accuracies on every epoch.\n",
    "\n",
    "If your implementation of forward and backward are correct, your accuracy should grow from 90~93% to >97% with default network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "As usual, we split data into minibatches, feed each such minibatch into a network and update weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.random.permutation(len(inputs))\n",
    "    for start_idx in trange(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "train_log = []\n",
    "val_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n",
      "Train accuracy: 0.99998\n",
      "Val accuracy: 0.9803\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28616170e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(25):\n",
    "\n",
    "    for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=32,shuffle=True):\n",
    "        train(network,x_batch,y_batch)\n",
    "    \n",
    "    train_log.append(np.mean(predict(network,X_train)==y_train))\n",
    "    val_log.append(np.mean(predict(network,X_val)==y_val))\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"Epoch\",epoch)\n",
    "    print(\"Train accuracy:\",train_log[-1])\n",
    "    print(\"Val accuracy:\",val_log[-1])\n",
    "    plt.plot(train_log,label='train accuracy')\n",
    "    plt.plot(val_log,label='val accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98119999999999996"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set Accuracy\n",
    "np.mean(predict(network,X_test)==y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peer-reviewed assignment\n",
    "\n",
    "Congradulations, you managed to get this far! There is just one quest left undone, and this time you'll get to choose what to do.\n",
    "\n",
    "\n",
    "#### Option I: initialization\n",
    "* Implement Dense layer with Xavier initialization as explained [here](http://bit.ly/2vTlmaJ)\n",
    "\n",
    "To pass this assignment, you must conduct an experiment showing how xavier initialization compares to default initialization on deep networks (5+ layers).\n",
    "\n",
    "\n",
    "#### Option II: regularization\n",
    "* Implement a version of Dense layer with L2 regularization penalty: when updating Dense Layer weights, adjust gradients to minimize\n",
    "\n",
    "$$ Loss = Crossentropy + \\alpha \\cdot \\underset i \\sum {w_i}^2 $$\n",
    "\n",
    "To pass this assignment, you must conduct an experiment showing if regularization mitigates overfitting in case of abundantly large number of neurons. Consider tuning $\\alpha$ for better results.\n",
    "\n",
    "#### Option III: optimization\n",
    "* Implement a version of Dense layer that uses momentum/rmsprop or whatever method worked best for you last time.\n",
    "\n",
    "Most of those methods require persistent parameters like momentum direction or moving average grad norm, but you can easily store those params inside your layers.\n",
    "\n",
    "To pass this assignment, you must conduct an experiment showing how your chosen method performs compared to vanilla SGD.\n",
    "\n",
    "_Please read our peer-review guidelines before starting this part of the assignment._\n",
    "\n",
    "In short, a good solution is one that:\n",
    "* is based on this notebook\n",
    "* runs in default course environment with Run All\n",
    "* it's code doesn't cause spontaneous eye bleeding\n",
    "* it's report is easy to read.\n",
    "\n",
    "_Formally we can't ban you from writing boring reports, but if you bored your reviewer to death, there's noone left alive to give you the grade you want._\n",
    "\n",
    "### Bonus assignments\n",
    "\n",
    "As a bonus assignment (no points, just swag), consider implementing Batch Normalization ([guide](https://gab41.lab41.org/batch-normalization-what-the-hey-d480039a9e3b)) or Dropout ([guide](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)). Note, however, that those \"layers\" behave differently when training and when predicting on test set.\n",
    "\n",
    "* Dropout:\n",
    "  * During training: drop units randomly with probability __p__ and multiply everything by __1/(1-p)__\n",
    "  * During final predicton: do nothing; pretend there's no dropout\n",
    "  \n",
    "* Batch normalization\n",
    "  * During training, it substracts mean-over-batch and divides by std-over-batch and updates mean and variance.\n",
    "  * During final prediction, it uses accumulated mean and variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Implementation of Regularization\n",
    "\n",
    "I chose to extend the implementation with Regularization. Modified code is given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First modified the Dense Layer to have regularization\n",
    "# reg in init is the coefficient of regularization\n",
    "class Dense_reg(Layer):\n",
    "    def __init__(self,input_units,output_units,learning_rate=0.1, reg=0.001):\n",
    "        \"\"\"\n",
    "        A dense layer is a layer which performs a learned affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg = reg\n",
    "        \n",
    "        #initialize weights with small random numbers. We use normal initialization, \n",
    "        #but surely there is something better. Try this once you got it working: http://bit.ly/2vTlmaJ\n",
    "        self.weights = np.random.randn(input_units,output_units)*0.01\n",
    "        self.biases = np.zeros(output_units)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        Perform an affine transformation:\n",
    "        f(x) = <W*x> + b\n",
    "        \n",
    "        input shape: [batch, input_units]\n",
    "        output shape: [batch, output units]\n",
    "        \"\"\"\n",
    "        #<your code here>\n",
    "        return np.dot(input,self.weights) + self.biases \n",
    "    \n",
    "    def backward(self,input,grad_output):\n",
    "        \n",
    "        #compute d f / d x = d f / d dense * d dense / d x\n",
    "        #where d dense/ d x = weights transposed\n",
    "        #<your code here>\n",
    "        grad_input = np.dot(grad_output, self.weights.T) \n",
    "        \n",
    "        #compute gradient w.r.t. weights and biases\n",
    "        grad_weights = np.dot(input.T,grad_output)/input.shape[0] + self.reg * self.weights#<your code here>\n",
    "        grad_biases = grad_output.mean(axis=0) #<your code here>\n",
    "        \n",
    "        assert grad_weights.shape == self.weights.shape and grad_biases.shape == self.biases.shape\n",
    "        #Here we perform stochastic gradient descent step. \n",
    "        #later on, you can try replacing that with something better.\n",
    "        self.weights = self.weights - self.learning_rate*grad_weights\n",
    "        self.biases = self.biases - self.learning_rate*grad_biases\n",
    "        \n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the new network\n",
    "network_reg = []\n",
    "network_reg.append(Dense_reg(X_train.shape[1],100))\n",
    "network_reg.append(ReLU())\n",
    "network_reg.append(Dense_reg(100,200))\n",
    "network_reg.append(ReLU())\n",
    "network_reg.append(Dense_reg(200,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified the train function to include calculation of loss with regularization\n",
    "def train_reg(network,X,y,reg=0.001):\n",
    "    \"\"\"\n",
    "    Train your network on a given batch of X and y.\n",
    "    You first need to run forward to get all layer activations.\n",
    "    Then you can run layer.backward going from last to first layer.\n",
    "    \n",
    "    After you called backward for all layers, all Dense layers have already made one gradient step.\n",
    "    \"\"\"\n",
    "    \n",
    "    #get layer activations\n",
    "    layer_activations = forward(network,X)\n",
    "    layer_inputs = [X]+layer_activations  #layer_input[i] is an input for network[i]\n",
    "    logits = layer_activations[-1]\n",
    "    \n",
    "    #Compute loss and initial gradient\n",
    "    loss = softmax_crossentropy_with_logits(logits,y)\n",
    "    loss_grad = grad_softmax_crossentropy_with_logits(logits,y)\n",
    "    \n",
    "    #<your code: propagate gradients through the network>\n",
    "    for layer_i in range(len(network))[::-1]:\n",
    "        layer = network[layer_i]\n",
    "        \n",
    "        loss_grad = layer.backward(layer_inputs[layer_i],loss_grad) #grad w.r.t. input, also weight updates\n",
    "        if isinstance(layer, Dense_reg):\n",
    "            loss += 0.5 * reg * np.sum(layer.weights ** 2)\n",
    "        \n",
    "    return np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create empty array to hold training and testing loss\n",
    "train_log_reg = []\n",
    "val_log_reg = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n",
      "Train accuracy: 0.99022\n",
      "Val accuracy: 0.9779\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x286146874e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "\n",
    "    for x_batch,y_batch in iterate_minibatches(X_train,y_train,batchsize=32,shuffle=True):\n",
    "        train_reg(network_reg,x_batch,y_batch)\n",
    "    \n",
    "    train_log_reg.append(np.mean(predict(network_reg,X_train)==y_train))\n",
    "    val_log_reg.append(np.mean(predict(network_reg,X_val)==y_val))\n",
    "    \n",
    "    clear_output()\n",
    "    print(\"Epoch\",epoch)\n",
    "    print(\"Train accuracy:\",train_log_reg[-1])\n",
    "    print(\"Val accuracy:\",val_log_reg[-1])\n",
    "    plt.title(\"With Regulization\")\n",
    "    plt.plot(train_log_reg,label='train accuracy')\n",
    "    plt.plot(val_log_reg,label='val accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97909999999999997"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Set Accuracy\n",
    "np.mean(predict(network_reg,X_test)==y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_mag(network):\n",
    "    result = 0.0\n",
    "    for layer in network:\n",
    "        if isinstance(layer, Dense) or isinstance(layer, Dense_reg):\n",
    "            result += np.sum(np.abs(layer.weights))\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4328.2816950429442"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mag(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2288.1366987602969"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_mag(network_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Regularization Experiment\n",
    "\n",
    "The modifications needed to implement L2 regularization were two\n",
    "* Dense layer in the backward pass needs to add the weights to the gradient calculation. The code is implemented in `Dense_reg` function\n",
    "* training time, the loss needs to be calculated by adding the L2 penalty term. This is implemented is `train_reg`\n",
    "\n",
    "The network architecture was kep same- with and without regularization. L2 penalty coefficient used was \"0.001\" for the experiment. A higher reg coff caused the weights to die out and significantly degraded the quality of predictions.\n",
    "\n",
    "With these settings, regular network was run 25 epochs and it produced a result of \n",
    "* training accuracy ~ 100%\n",
    "* validation accuracy ~ 98.04%\n",
    "* test accuracy ~ 98.1%\n",
    "* total sum of weights ~ 4328\n",
    "\n",
    "The same newtwork with regularization peanlty coefficient of 0.001 was run through 30 epochs and it produced the following results:\n",
    "* training accuracy ~ 99%\n",
    "* validation accuracy ~ 97.8%\n",
    "* test accuracy ~ 97.9%\n",
    "* total sum of weights ~ 2288\n",
    "\n",
    "So from above we observe two things that regularization helped us achieve:\n",
    "* first the overfitting (as observed by difference between training and test error) was lesser in the network with regularization. Normal network had (training Acc - test Acc) of 1.9%. While the network with regularization had this at 1.2%\n",
    "\n",
    "* Second the total sum of weight magnitudes halved in the case the regularized network which leads to a more stable and generalised network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
